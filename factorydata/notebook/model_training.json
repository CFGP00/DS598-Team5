{
	"name": "model_training",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "model",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "51900f09-10bf-4f6b-a1dc-d43f45b85938"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/3b608a14-90b7-42d9-82e2-77c947974137/resourceGroups/DS562-Team-5/providers/Microsoft.Synapse/workspaces/sentiment-analyses/bigDataPools/model",
				"name": "model",
				"type": "Spark",
				"endpoint": "https://sentiment-analyses.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/model",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from azure.storage.blob import BlobServiceClient\n",
					"from io import BytesIO\n",
					"import pandas as pd\n",
					"\n",
					"connection_string = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
					"\n",
					"container_name = \"team5container\"\n",
					"blob_path = \"Gold/Historical Stock/apple_ticker.parquet\"\n",
					"\n",
					"blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
					"blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_path)\n",
					"\n",
					"stream = BytesIO()\n",
					"blob_client.download_blob().readinto(stream)\n",
					"stream.seek(0)\n",
					"\n",
					"df_h = pd.read_parquet(stream)\n",
					"df_h.head()"
				],
				"execution_count": 100
			},
			{
				"cell_type": "code",
				"source": [
					"connection_string = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
					"\n",
					"container_name = \"team5container\"\n",
					"blob_path = \"Gold/News/news_with_sentiment.parquet\"\n",
					"\n",
					"blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
					"blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_path)\n",
					"\n",
					"stream = BytesIO()\n",
					"blob_client.download_blob().readinto(stream)\n",
					"stream.seek(0)\n",
					"\n",
					"df_n = pd.read_parquet(stream)\n",
					"df_n.head()"
				],
				"execution_count": 101
			},
			{
				"cell_type": "code",
				"source": [
					"connection_string = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
					"\n",
					"container_name = \"team5container\"\n",
					"blob_path = \"Gold/Product Reviews/reviews_with_sentiment.parquet\"\n",
					"\n",
					"blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
					"blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_path)\n",
					"\n",
					"stream = BytesIO()\n",
					"blob_client.download_blob().readinto(stream)\n",
					"stream.seek(0)\n",
					"\n",
					"df_r = pd.read_parquet(stream)\n",
					"df_r.head()"
				],
				"execution_count": 102
			},
			{
				"cell_type": "code",
				"source": [
					"connection_string = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
					"\n",
					"container_name = \"team5container\"\n",
					"blob_path = \"Gold/Search Trends/trends_with_sentiment.parquet\"\n",
					"\n",
					"blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
					"blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_path)\n",
					"\n",
					"stream = BytesIO()\n",
					"blob_client.download_blob().readinto(stream)\n",
					"stream.seek(0)\n",
					"\n",
					"df_t = pd.read_parquet(stream)\n",
					"df_t.head()"
				],
				"execution_count": 103
			},
			{
				"cell_type": "code",
				"source": [
					"# Strip column names to avoid hidden whitespaces\n",
					"for df in [df_n, df_r, df_t]:\n",
					"    df.columns = df.columns.str.strip().str.lower()\n",
					"\n",
					"# Convert 'sentiment' column from text to numeric\n",
					"sentiment_map = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
					"\n",
					"df_n['sentiment'] = df_n['sentiment'].map(sentiment_map)\n",
					"df_r['sentiment'] = df_r['sentiment'].map(sentiment_map)\n",
					"df_t['sentiment'] = df_t['sentiment'].map(sentiment_map)"
				],
				"execution_count": 104
			},
			{
				"cell_type": "code",
				"source": [
					"# Aggregate news sentiment\n",
					"df_news_daily = df_n.groupby('date', as_index=False)['sentiment'].mean()\n",
					"df_news_daily.rename(columns={'sentiment': 'sentiment_news'}, inplace=True)\n",
					"\n",
					"# Aggregate reviews sentiment\n",
					"df_reviews_daily = df_r.groupby('date', as_index=False)['sentiment'].mean()\n",
					"df_reviews_daily.rename(columns={'sentiment': 'sentiment_reviews'}, inplace=True)"
				],
				"execution_count": 105
			},
			{
				"cell_type": "code",
				"source": [
					"# Make sure date is datetime\n",
					"df_t['date'] = pd.to_datetime(df_t['date'])\n",
					"\n",
					"# Set date as index and resample to daily frequency\n",
					"df_search_daily = df_t.set_index('date').resample('D').ffill().reset_index()\n",
					"df_search_daily.rename(columns={'sentiment': 'sentiment_search'}, inplace=True)"
				],
				"execution_count": 106
			},
			{
				"cell_type": "code",
				"source": [
					"# News sentiment\n",
					"df_news = df_n[['date', 'sentiment']].copy()\n",
					"df_news.rename(columns={'sentiment': 'sentiment_news'}, inplace=True)\n",
					"\n",
					"# Product reviews sentiment\n",
					"df_reviews = df_r[['date', 'sentiment']].copy()\n",
					"df_reviews.rename(columns={'sentiment': 'sentiment_reviews'}, inplace=True)\n",
					"\n",
					"# Search trend sentiment (already resampled in earlier step)\n",
					"df_search = df_search_daily[['date', 'sentiment_search']].copy()"
				],
				"execution_count": 107
			},
			{
				"cell_type": "code",
				"source": [
					"df_h['date'] = pd.to_datetime(df_h['date'])\n",
					"df_news['date'] = pd.to_datetime(df_news['date'])\n",
					"df_reviews['date'] = pd.to_datetime(df_reviews['date'])\n",
					"df_search['date'] = pd.to_datetime(df_search['date'])"
				],
				"execution_count": 108
			},
			{
				"cell_type": "code",
				"source": [
					"df_h['date'] = pd.to_datetime(df_h['date'])  # ensure datetime\n",
					"\n",
					"df = df_h.merge(df_news, on='date', how='left') \\\n",
					"         .merge(df_reviews, on='date', how='left') \\\n",
					"         .merge(df_search, on='date', how='left')"
				],
				"execution_count": 280
			},
			{
				"cell_type": "code",
				"source": [
					"# Keep the first occurrence for each unique date\n",
					"df = df.drop_duplicates(subset='date', keep='first').reset_index(drop=True)\n",
					"df['sentiment_news'] = pd.to_numeric(df['sentiment_news'], errors='coerce').fillna(0).astype(int)\n",
					"df['sentiment_reviews'] = pd.to_numeric(df['sentiment_reviews'], errors='coerce').fillna(0).astype(int)\n",
					"df['sentiment_search'] = pd.to_numeric(df['sentiment_search'], errors='coerce').fillna(0).astype(int)"
				],
				"execution_count": 289
			},
			{
				"cell_type": "code",
				"source": [
					"df.head(10)"
				],
				"execution_count": 290
			},
			{
				"cell_type": "code",
				"source": [
					"df['sentiment_reviews'].value_counts()"
				],
				"execution_count": 291
			},
			{
				"cell_type": "code",
				"source": [
					"df.shape"
				],
				"execution_count": 292
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"\n",
					"# Ensure datetime\n",
					"df['date'] = pd.to_datetime(df['date'])\n",
					"\n",
					"# Sort by date\n",
					"df = df.sort_values('date').reset_index(drop=True)\n",
					"\n",
					"# Optional sanity check\n",
					"df[['date', 'Close', 'Open', 'High', 'Low', 'Volume', 'sentiment_news', 'sentiment_reviews', 'sentiment_search']].head()"
				],
				"execution_count": 400
			},
			{
				"cell_type": "code",
				"source": [
					"features = df[['Open', 'High', 'Low', 'Close', 'Volume', \n",
					"               'sentiment_news', 'sentiment_reviews', 'sentiment_search']]\n",
					"target_col = 'Close'"
				],
				"execution_count": 401
			},
			{
				"cell_type": "code",
				"source": [
					"from sklearn.preprocessing import MinMaxScaler\n",
					"\n",
					"scaler = MinMaxScaler()\n",
					"scaled_features = scaler.fit_transform(features)"
				],
				"execution_count": 402
			},
			{
				"cell_type": "code",
				"source": [
					"print(\"X shape:\", X.shape)  # Expected: (samples, 30, 8)\n",
					"print(\"y shape:\", y.shape)  # Expected: (samples,)"
				],
				"execution_count": 405
			},
			{
				"cell_type": "code",
				"source": [
					"import numpy as np\n",
					"\n",
					"window_size = 30\n",
					"X = []\n",
					"y = []\n",
					"\n",
					"for i in range(window_size, len(scaled_features)):\n",
					"    X.append(scaled_features[i-window_size:i])\n",
					"    y.append(scaled_features[i][3])  # 3 is index of 'Close' in features\n",
					"\n",
					"X, y = np.array(X), np.array(y)"
				],
				"execution_count": 404
			},
			{
				"cell_type": "code",
				"source": [
					"split_index = int(len(X) * 0.8)\n",
					"X_train, X_val = X[:split_index], X[split_index:]\n",
					"y_train, y_val = y[:split_index], y[split_index:]"
				],
				"execution_count": 406
			},
			{
				"cell_type": "code",
				"source": [
					"from tensorflow.keras.models import Sequential\n",
					"from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
					"from tensorflow.keras.callbacks import EarlyStopping\n",
					"from tensorflow.keras.optimizers import Adam\n",
					"\n",
					"model = Sequential()\n",
					"model.add(LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
					"model.add(Dropout(0.2))\n",
					"model.add(LSTM(32))\n",
					"model.add(Dropout(0.2))\n",
					"model.add(Dense(1))\n",
					"\n",
					"model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')\n",
					"\n",
					"early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
					"\n",
					"history = model.fit(\n",
					"    X_train, y_train,\n",
					"    validation_data=(X_val, y_val),\n",
					"    epochs=50,\n",
					"    batch_size=8,\n",
					"    callbacks=[early_stop],\n",
					"    verbose=1\n",
					")"
				],
				"execution_count": 407
			},
			{
				"cell_type": "code",
				"source": [
					"predictions = model.predict(X_val)\n",
					"\n",
					"# Inverse transform only the 'Close' column\n",
					"predicted_full = np.zeros((len(predictions), scaled_features.shape[1]))\n",
					"actual_full = np.zeros((len(y_val), scaled_features.shape[1]))\n",
					"\n",
					"predicted_full[:, 3] = predictions[:, 0]\n",
					"actual_full[:, 3] = y_val\n",
					"\n",
					"predicted_close = scaler.inverse_transform(predicted_full)[:, 3]\n",
					"actual_close = scaler.inverse_transform(actual_full)[:, 3]"
				],
				"execution_count": 408
			},
			{
				"cell_type": "code",
				"source": [
					"from sklearn.metrics import mean_squared_error\n",
					"import numpy as np\n",
					"\n",
					"rmse = np.sqrt(mean_squared_error(actual_close, predicted_close))\n",
					"print(f\"Root Mean Squared Error: {rmse:.2f}\")"
				],
				"execution_count": 409
			},
			{
				"cell_type": "code",
				"source": [
					"import matplotlib.pyplot as plt\n",
					"\n",
					"# Get test dates (aligned with validation set)\n",
					"test_dates = df['date'][window_size + split_index:]\n",
					"\n",
					"plt.figure(figsize=(14, 7))\n",
					"plt.plot(test_dates, actual_close, label='Actual Closing Price', color='blue')\n",
					"plt.plot(test_dates, predicted_close, label='Predicted Closing Price', color='orange')\n",
					"plt.title(\"LSTM Model â€” Apple Stock Price Prediction\")\n",
					"plt.xlabel(\"Date\")\n",
					"plt.ylabel(\"Price\")\n",
					"plt.legend()\n",
					"plt.grid(True)\n",
					"plt.tight_layout()\n",
					"plt.show()"
				],
				"execution_count": 410
			},
			{
				"cell_type": "code",
				"source": [
					"import matplotlib.pyplot as plt\n",
					"\n",
					"plt.figure(figsize=(10, 5))\n",
					"plt.plot(history.history['loss'], label='Training Loss')\n",
					"plt.plot(history.history['val_loss'], label='Validation Loss')\n",
					"plt.title('Training vs Validation Loss')\n",
					"plt.xlabel('Epoch')\n",
					"plt.ylabel('MSE Loss')\n",
					"plt.legend()\n",
					"plt.grid(True)\n",
					"plt.show()\n",
					""
				],
				"execution_count": 411
			},
			{
				"cell_type": "code",
				"source": [
					"from sklearn.preprocessing import MinMaxScaler\n",
					"\n",
					"# Define only the numeric columns used during model training\n",
					"feature_columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'sentiment_news', 'sentiment_reviews', 'sentiment_search']\n",
					"\n",
					"# Select only those from the DataFrame\n",
					"features = df[feature_columns].astype(float).values  # <-- Ensures no timestamps\n",
					"\n",
					"# Fit or reuse your scaler\n",
					"scaler = MinMaxScaler()\n",
					"scaled_features = scaler.fit_transform(features)  # Or use scaler.transform(features) if already fitted\n",
					"\n",
					"# Define window size again if needed\n",
					"window_size = 30\n",
					"\n",
					"# Use last 30 days to predict the next\n",
					"last_window = scaled_features[-window_size:]\n",
					"input_data = np.expand_dims(last_window, axis=0)\n",
					"\n",
					"predicted_scaled_close = model.predict(input_data)\n",
					"\n",
					"temp_array = np.zeros((1, scaled_features.shape[1]))\n",
					"temp_array[0, ] = predicted_scaled_close  \n",
					"\n",
					"predicted_close_apr21 = scaler.inverse_transform(temp_array)[0, 3]\n",
					"print(f\"ðŸ“ˆ Predicted Closing Price for April 21, 2025: ${predicted_close_apr21:.2f}\")"
				],
				"execution_count": 412
			},
			{
				"cell_type": "code",
				"source": [
					"plt.figure(figsize=(6, 6))\n",
					"plt.scatter(actual_close, predicted_close, alpha=0.5, color='blue')\n",
					"plt.plot([min(actual_close), max(actual_close)],\n",
					"         [min(actual_close), max(actual_close)], 'r--')\n",
					"plt.xlabel(\"Actual Close Price\")\n",
					"plt.ylabel(\"Predicted Close Price\")\n",
					"plt.title(\"Actual vs Predicted Close Prices\")\n",
					"plt.grid(True)\n",
					"plt.show()"
				],
				"execution_count": 413
			},
			{
				"cell_type": "code",
				"source": [
					"from sklearn.metrics import mean_absolute_error, r2_score\n",
					"\n",
					"mae = mean_absolute_error(actual_close, predicted_close)\n",
					"r2 = r2_score(actual_close, predicted_close)\n",
					"\n",
					"print(f\"MAE: {mae:.4f}\")\n",
					"print(f\"RÂ² Score: {r2:.4f}\")"
				],
				"execution_count": 414
			},
			{
				"cell_type": "code",
				"source": [
					"import matplotlib.pyplot as plt\n",
					"import seaborn as sns\n",
					"\n",
					"# Summary stats\n",
					"print(df_h.describe())\n",
					"\n",
					"# Closing price trend\n",
					"plt.figure(figsize=(14, 5))\n",
					"plt.plot(df_h['date'], df_h['Close'], label='Close Price')\n",
					"plt.title('AAPL Closing Price Over Time')\n",
					"plt.xlabel('Date')\n",
					"plt.ylabel('Price')\n",
					"plt.grid(True)\n",
					"plt.legend()\n",
					"plt.show()\n",
					"\n",
					"# Volume trend\n",
					"plt.figure(figsize=(14, 5))\n",
					"plt.plot(df_h['date'], df_h['Volume'], label='Volume', color='orange')\n",
					"plt.title('Trading Volume Over Time')\n",
					"plt.xlabel('Date')\n",
					"plt.ylabel('Volume')\n",
					"plt.grid(True)\n",
					"plt.legend()\n",
					"plt.show()"
				],
				"execution_count": 416
			},
			{
				"cell_type": "code",
				"source": [
					"# Sentiment distribution\n",
					"sns.countplot(data=df_n, x='sentiment', palette='viridis')\n",
					"plt.title('News Sentiment Distribution')\n",
					"plt.show()\n",
					"\n",
					"# Sentiment distribution\n",
					"sns.countplot(data=df_t, x='sentiment', palette='cool')\n",
					"plt.title('Search Trend Sentiment Distribution')\n",
					"plt.show()\n",
					"\n",
					"# Sentiment distribution\n",
					"sns.countplot(data=df, x='sentiment_reviews', palette='Set2')\n",
					"plt.title('Product Review Sentiment Distribution')\n",
					"plt.show()"
				],
				"execution_count": 417
			},
			{
				"cell_type": "code",
				"source": [
					"# Now you can create the LSTM results DataFrame\n",
					"lstm_results = pd.DataFrame({\n",
					"    'date': test_dates,\n",
					"    'actual_close': actual_close,\n",
					"    'predicted_close': predicted_close\n",
					"})\n",
					"\n",
					"lstm_results.head(20)"
				],
				"execution_count": 422
			},
			{
				"cell_type": "code",
				"source": [
					""
				],
				"execution_count": null
			}
		]
	}
}